# Tic Tac Toe With TypeScript

## Overview

Thanks for checking out this front-end coding challenge.

This is a classic Tic Tac Toe game featuring multiplayer or VS CPU game modes, along with various difficulty settings.

[Live Demo](https://emretantu.github.io/tic-tac-toe-typescript/)

## Table of Contents
- [Project source](#project-source)
- [The challenge](#the-challenge)
- [Screenshot](#screenshot)
- [Links](#links)
- [Built with (tech-stack)](#built-with-tech-stack)
- [What you need to know](#what-you-need-to-know)
- [The Minimax Algorithm and the Strategic Humanization of AI](#the-minimax-algorithm-and-the-strategic-humanization-of-ai)
- [Author](#author)

## Project source

This is a Frontend Mentor project. You can find the details under [Useful resources](#useful-resources).

## The challenge

Users should be able to:

- View the optimal layout for the game depending on their device's screen size
- See hover states for all interactive elements on the page
- Play the game either solo vs the computer or multiplayer against another person
- **Bonus 1**: Save the game state in the browser so that itâ€™s preserved if the player refreshes their browser
- **Bonus 2**: Instead of having the computer randomly make its moves, try making it clever so itâ€™s proactive in blocking your moves and trying to win
- **Bonus 3**: If your "clever" approach uses the **Minimax algorithm**, the human player will have no chance of winning; they will either tie or lose. To overcome this, you can adjust the Minimax logic to allow for human wins and even implement different difficulty modes.

**Expected behavior**

- You can choose to make the default screen either the new game menu or the solo player game board. Note that we're using the solo player game board for the design screenshot, so if you choose the new game menu it won't match up in the design comparison slider. This isn't a big deal, but is something worth considering.
- On the new game screen, whichever mark isn't selected for the first player is automatically assigned to the second player when the game is started.
- The first turn of the first round is always played by whoever is playing as X. For every following round, the first turn alternates between O and X.
- After a round, if the player chooses to quit the game, they should be taken back to the new game menu.
- If the restart icon in the top right is clicked, the "Restart game?" modal should show and allow the player to reset the game or cancel and continue to play.

## Screenshot

<img src="./screenshots/tic-tac-toe-gaming.png" height="300px"> <img src="./screenshots/tic-tac-toe-start-screen.png" height="300px"> <img src="./screenshots/tic-tac-toe-restart-game-modal.png" height="300px">

<img src="./screenshots/tic-tac-toe-round-tied-modal.png" height="300px"> <img src="./screenshots/tic-tac-toe-x-takes-the-round-modal.png" height="300px"> <img src="./screenshots/tic-tac-toe-o-takes-the-round-modal.png" height="300px">

## Links

- [Live Demo](https://emretantu.github.io/tic-tac-toe-typescript/)
- [Frontend Mentor Tic Tac Toe Challenge](https://www.frontendmentor.io/challenges/tic-tac-toe-game-Re7ZF_E2v)

## Built with (tech stack)

- HTML
- CSS
- TypeScript

## What You Need to Know

- The tech stack listed above
- TS concepts and features

## The Minimax Algorithm and the Strategic Humanization of AI

In "VS CPU" mode, the game becomes uninteresting if the computer only makes random moves. The most established method for creating intelligent opponents is the **Minimax algorithm**. In short, Minimax operates on the premise that the opponent will always play optimally, leading the AI to seek the most secure path. It constructs a decision tree of all possible moves from the current **state** until it reaches the end of the game. Each **node** represents a state, and each connection represents a move. The **leaf nodes** represent the **terminal states**: typically, a computer win is scored as +1, a draw as 0, and a human win as -1.

At each depth, the algorithm checks the child nodes of the current player. The **maximizer** (the computer) tries to maximize the score by avoiding branches that lead to low values. When it is the **minimizer's** (human) turn, the goal is to choose the lowest possible value. These values propagate from the terminal states back to the **root state**, allowing the computer to select the move with the highest guaranteed score.

**The First Problem**: When we assign fixed values like +1 for a win, 0 for a draw, and -1 for a loss, Minimax suffers from "depth blindness." Because the algorithm utilizes **Depth First Search (DFS)**, it sees no difference between a win in 1 move and a win in 5 moves. If it discovers a distant win last, it may prioritize it over an immediate win. To a human player, this looks irrational or as if the computer is "toying with its prey," which can be frustrating.

To solve this, I made the algorithm **depth-aware**. I subtracted the depth from winning scores and added it to losing scores. I calibrated the scoring system so that even the most distant win remains at least +1. This ensures that Minimax chooses not just the most guaranteed path, but also the **shortest path** to victory.

**The Second Problem**: A perfectly implemented Minimax algorithm is unbeatable; it either wins or forces a draw. While this solves the problem of "random play," it introduces the boredom of an "impossible game." Playing against a machine that never makes a mistake is discouraging. A common fix is to make the AI play the best move 90% of the time and a random move 10% of the time. However, this feels unrealistic, as an otherwise brilliant AI might suddenly miss a glaringly obvious winning move.

**The Solution**: Instead of simply picking the best move, my implementation records all possible moves and their values into an array, sorted from the best possible outcome to the worst. Human players generally try to make the best move they can see, which is often close toâ€”but not always exactlyâ€”the absolute optimal move. 

To select a move from this sorted list, consider this linear formula:

$$\text{floor}(r \times \text{MovesArrayLength}), \quad r \in [0,1)$$

This gives every move an equal probability, which reverts the game to random play. However, by applying an exponent ($P$) to the random variable $r$, we can bend the probability curve:

$$\text{floor}\big((r^{P}) \times \text{MovesArrayLength}\big), \quad r \in [0,1), \; P > 0$$

As $P$ increases, the results gravitate heavily toward 0 (the best move). Even though $r$ is a random value between [0, 1), the result of $r^P$ yields values much closer to 0. This allows the AI to prioritize the optimal move while occasionally choosing "near-optimal" alternatives. The probability of selecting a disastrously bad move becomes nearly zero.

I categorized the difficulty levels based on these $P$ values:

```ts
enum Difficulty {
  Noob = 1,
  Easy = 2,
  Medium = 4,
  Hard = 16,
  Imposible = 0
}
```
Impossible (0) mode, the probabilistic formula is bypassed, and the algorithm plays a flawless, unbeatable game by directly selecting the optimal move from the original Minimax.

## Author

**Emre Tantu**
- Website - [emretantu.dev](https://www.emretantu.dev)
- Contact - [hello@emretantu.dev](mailto:hello@emretantu.dev)
- LinkedIn - [in/emretantu](https://www.linkedin.com/in/emretantu/)
- Twitter - [@emretantu](https://www.twitter.com/emretantu)

---
---

# ğŸ‡¹ğŸ‡· Tic Tac Toe - TypeScript Ä°le

## Genel BakÄ±ÅŸ

Bu front-end coding challenge projesine gÃ¶z attÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler.

Bu proje, multiplayer veya CPU'ya karÅŸÄ± oyun modlarÄ± ve zorluk seÃ§enekleri sunan klasik bir Tic Tac Toe oyunudur.

[Live Demo](https://emretantu.github.io/tic-tac-toe-typescript/)

## Ä°Ã§indekiler
- [Proje kaynaÄŸÄ±](#proje-kaynagi)
- [Ä°sterler (Gereksinimler)](#isterler-gereksinimler)
- [Ekran GÃ¶rÃ¼ntÃ¼leri](#ekran-goruntuleri)
- [Linkler](#linkler)
- [KullanÄ±lan Teknolojiler](#kullanilan-teknolojiler)
- [Bilmeniz Gerekenler](#bilmeniz-gerekenler)
- [Minimax AlgoritmasÄ± ve Minimax'i "Ä°nsanlaÅŸtÄ±rmanÄ±n" En Ä°yi Yolu](#minimax-algoritmasÄ±-ve-minimaxi-iÌ‡nsanlaÅŸtÄ±rmanÄ±n-en-iÌ‡yi-yolu)
- [Yazar](#yazar)

## Proje kaynaÄŸÄ±

Bu bir Frontend Mentor projesidir. DetaylarÄ± [Useful resources](#useful-resources) altÄ±nda bulabilirsiniz.

## Ä°sterler (Gereksinimler)

KullanÄ±cÄ± ÅŸunlarÄ± yapabilmelidir:

- Cihaz ekran boyutuna gÃ¶re optimize edilmiÅŸ **layout**'u gÃ¶rebilmeli.
- Sayfadaki tÃ¼m interaktif elementler iÃ§in **hover state**'lerini gÃ¶rebilmeli.
- Oyunu bilgisayara karÅŸÄ± (solo) veya baÅŸka birine karÅŸÄ± (multiplayer) oynayabilmeli.
- **Bonus 1**: Oyunun durumunu (**state**) tarayÄ±cÄ±da kaydedebilmeli, bÃ¶ylece sayfa yenilendiÄŸinde ilerleme korunmalÄ±.
- **Bonus 2**: BilgisayarÄ±n rastgele hamle yapmasÄ± yerine, hamleleri Ã¶nceden sezip engelleyen ve kazanmaya Ã§alÄ±ÅŸan zeki bir mantÄ±k kurgulanmalÄ±.
- **Bonus 3**: EÄŸer zeki yÃ¶nteminiz **Minimax algoritmasÄ±** ise, insan oyuncunun kazanma ÅŸansÄ± olmayacaktÄ±r; ya berabere kalacak ya da kaybedecektir. Bu durumu aÅŸmak iÃ§in **Minimax** mantÄ±ÄŸÄ±nÄ± esnetebilir ve farklÄ± zorluk modlarÄ± ekleyebilirsiniz.

**Beklenen DavranÄ±ÅŸlar**

- VarsayÄ±lan ekranÄ± "Yeni Oyun MenÃ¼sÃ¼" veya "Solo Oyun TahtasÄ±" olarak seÃ§ebilirsiniz. (Ekran gÃ¶rÃ¼ntÃ¼lerinde solo tahta kullanÄ±ldÄ±ÄŸÄ± iÃ§in tasarÄ±m karÅŸÄ±laÅŸtÄ±rmasÄ±nda bu durum dikkate alÄ±nmalÄ±dÄ±r).
- Yeni oyun ekranÄ±nda, birinci oyuncu iÃ§in seÃ§ilmeyen iÅŸaret, oyun baÅŸladÄ±ÄŸÄ±nda otomatik olarak ikinci oyuncuya atanÄ±r.
- Ä°lk turun ilk hamlesini her zaman X olarak oynayan yapar. Sonraki her turda, ilk hamle O ve X arasÄ±nda deÄŸiÅŸir.
- Bir turdan sonra, oyuncu oyundan Ã§Ä±kmak isterse ana menÃ¼ye yÃ¶nlendirilmelidir.
- SaÄŸ Ã¼stteki **restart** ikonuna tÄ±klandÄ±ÄŸÄ±nda, "Oyunu sÄ±fÄ±rla?" (**Restart game?**) **modal**'Ä± gÃ¶rÃ¼nmeli; oyuncu oyunu sÄ±fÄ±rlayabilmeli veya iptal edip devam edebilmeli.

## Ekran GÃ¶rÃ¼ntÃ¼leri

<img src="./screenshots/tic-tac-toe-gaming.png" height="300px"> <img src="./screenshots/tic-tac-toe-start-screen.png" height="300px"> <img src="./screenshots/tic-tac-toe-restart-game-modal.png" height="300px">

<img src="./screenshots/tic-tac-toe-round-tied-modal.png" height="300px"> <img src="./screenshots/tic-tac-toe-x-takes-the-round-modal.png" height="300px"> <img src="./screenshots/tic-tac-toe-o-takes-the-round-modal.png" height="300px">

## Linkler

- [Live Demo](https://emretantu.github.io/tic-tac-toe-typescript/)
- [Frontend Mentor Tic Tac Toe Challenge](https://www.frontendmentor.io/challenges/tic-tac-toe-game-Re7ZF_E2v)

## KullanÄ±lan Teknolojiler

- HTML
- CSS
- TypeScript

## Bilmeniz Gerekenler

- YukarÄ±daki **tech stack** bilgisi.
- TypeScript konseptleri ve Ã¶zellikleri.

## Minimax AlgoritmasÄ± ve Minimax'i "Ä°nsanlaÅŸtÄ±rmanÄ±n" En Ä°yi Yolu

"VS CPU" modunda bilgisayarÄ±n sadece rastgele hamleler yapmasÄ± oyun deneyimini verimsizleÅŸtirir. BilgisayarÄ± akÄ±llÄ± hale getirmenin en kabul gÃ¶rmÃ¼ÅŸ yolu **Minimax** algoritmasÄ±dÄ±r. Bu algoritma Ã¶zetle ÅŸunu yapar: Bilgisayar, rakibinin de her zaman en optimal hamleyi yapacaÄŸÄ±nÄ± varsayarak en garantici stratejiyi arar. Bu noktada mevcut durumdan (**state**) yapÄ±labilecek olasÄ± hamlelerle final durumlara ulaÅŸÄ±larak bir karar aÄŸacÄ± oluÅŸturulur. Her **node** bir durumu, her baÄŸlantÄ± ise bir hamleyi temsil eder. **Leaf node**'lar ise oyunun bitiÅŸ durumlarÄ±nÄ± (**terminal state**) temsil eder: Genelde bilgisayarÄ±n kazanmasÄ± +1, beraberlik 0, rakibin (insan oyuncu) kazanmasÄ± ise -1 olarak puanlanÄ±r.

Her derinlikte hamle sÄ±rasÄ± kimdeyse o dÃ¼ÄŸÃ¼mÃ¼n alt dallarÄ±na bakÄ±lÄ±r; **maximizer** (bilgisayar) kÃ¼Ã§Ã¼k deÄŸerlerin olduÄŸu yapraklardan kaÃ§Ä±narak puanÄ± maksimize etmeye Ã§alÄ±ÅŸÄ±r. SÄ±ra **minimizer** tarafÄ±ndayken tam tersi bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla en dÃ¼ÅŸÃ¼k deÄŸer hedeflenir. DeÄŸerler bu ÅŸekilde terminal state'lerden **root state**'e doÄŸru taÅŸÄ±nÄ±r ve bilgisayar kendisi iÃ§in en yÃ¼ksek puanlÄ± hamleyi seÃ§erek garantici bir oyun sergiler.

**Birinci Sorun**: Minimax'te kazanÃ§ durumunu +1, beraberlik durumunu 0, kaybetme durumunu -1 olarak atadÄ±ÄŸÄ±mÄ±zda "derinlik kÃ¶rlÃ¼ÄŸÃ¼" oluÅŸur. Algoritma **Depth First Search (DFS)** mantÄ±ÄŸÄ±yla Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in aÄŸacÄ±n sÄ±ÄŸ kÄ±sÄ±mlarÄ±ndaki (hemen gerÃ§ekleÅŸecek) bir galibiyet ile Ã§ok daha derindeki bir galibiyet arasÄ±nda puan farkÄ± gÃ¶rmez. EÄŸer algoritma en son derindeki bir kazanÃ§ durumunu keÅŸfettiyse, bariz olan kÄ±sa yolu bÄ±rakÄ±p o hamleyi seÃ§ebilir. Bu da insan oyuncu gÃ¶zÃ¼nde bilgisayarÄ±n rasyonel olmayan bir hamle yaptÄ±ÄŸÄ± veya "avÄ±yla oynadÄ±ÄŸÄ±" hissini uyandÄ±rarak sinir bozucu olabilir.

Bu sorunu Ã§Ã¶zmek iÃ§in algoritmayÄ± derinlik duyarlÄ± (**depth-aware**) hale getirdim. KazanÃ§ durumunda galibiyet puanÄ±ndan derinliÄŸi Ã§Ä±kardÄ±m; kayÄ±p durumunda ise puanÄ±na derinliÄŸi ekledim. Puan sistemini, en derindeki bir kazancÄ±n bile en az +1 kalacaÄŸÄ± ÅŸekilde ayarladÄ±m. BÃ¶ylece Minimax sadece en garantici yolu deÄŸil, aynÄ± zamanda **en kÄ±sa yolu** tercih eder hale geldi.

**Ä°kinci Sorun**: Kusursuz bir Minimax algoritmasÄ± asla kaybetmez; ya kazanÄ±r ya berabere kalÄ±r. Bu durum, "rastgele oyun" sÄ±kÄ±cÄ±lÄ±ÄŸÄ±ndan kaÃ§arken "imkansÄ±z oyun" sÄ±kÄ±cÄ±lÄ±ÄŸÄ±na dÃ¼ÅŸmemize neden olur. HatasÄ±z bir makineye karÅŸÄ± oynamak keyifsizdir. BilgisayarÄ±n tÄ±pkÄ± insanlar gibi makul hatalar yapmasÄ± iÃ§in genelde "en iyi hamleyi %90 ihtimalle yap, %10 ihtimalle rastgele oyna" mantÄ±ÄŸÄ± kullanÄ±lÄ±r. Ancak bu, Ã§ok akÄ±llÄ±ca oynayan birinin aniden gÃ¼n gibi ortada olan bir hamleyi kaÃ§Ä±rmasÄ± gibi gerÃ§ek dÄ±ÅŸÄ± durumlara yol aÃ§ar.

**Ã‡Ã¶zÃ¼m**: Minimax her adÄ±mda en iyi hamleyi bulduÄŸunda onu doÄŸrudan uygulamak yerine, bulduÄŸu tÃ¼m hamleleri deÄŸerleriyle birlikte bir diziye kaydeder ve bunlarÄ± en iyi kazanÃ§tan en kÃ¶tÃ¼ kayba doÄŸru sÄ±ralar. Ä°nsanlar da aslÄ±nda yapabildikleri en iyi hamleyi yaparlar ama bu bazen "mutlak en iyi"den biraz daha zayÄ±f olabilir. 

SÄ±ralanmÄ±ÅŸ hamle listesinden seÃ§im yaparken ÅŸu lineer formÃ¼lÃ¼ dÃ¼ÅŸÃ¼nelim:

$$\text{floor}(r \times \text{MovesArrayLength}), \quad r \in [0,1)$$

Bu formÃ¼l her hamleye eÅŸit seÃ§ilme ÅŸansÄ± verir ki bu da oyunu tekrar tamamen rastgele yapar. Ancak random Ã¼retilen $r$ deÄŸerinin kuvvetini ($P$) alÄ±rsak grafik bÃ¼kÃ¼lÃ¼r:

$$\text{floor}\big((r^{P}) \times \text{MovesArrayLength}\big), \quad r \in [0,1), \; P > 0$$

$P$ deÄŸerini artÄ±rdÄ±kÃ§a sonuÃ§lar dramatik bir ÅŸekilde 0'a (yani en iyi hamleye) yÄ±ÄŸÄ±lÄ±r. $r$ [0, 1) aralÄ±ÄŸÄ±nda rastgele olsa bile, $r^P$ deÄŸeri 0'a Ã§ok daha yakÄ±n sonuÃ§lar Ã¼retir. BÃ¶ylece bilgisayar yÃ¼ksek ihtimalle en iyi hamleyi, dÃ¼ÅŸÃ¼k ihtimalle ise en iyiye en yakÄ±n "makul" hamleleri seÃ§er. Ã‡ok kÃ¶tÃ¼ hamlelerin seÃ§ilme ihtimali ise neredeyse sÄ±fÄ±ra iner.

Zorluk dÃ¼zeylerini bu $P$ deÄŸerlerine gÃ¶re ÅŸu ÅŸekilde isimlendirdim:

```ts
enum Difficulty {
  Noob = 1,
  Easy = 2,
  Medium = 4,
  Hard = 16,
  Imposible = 0
}
```
Impossible (0) durumunda olasÄ±lÄ±k formÃ¼lÃ¼ uygulanmaz; algoritma doÄŸrudan orijinal Minimax'in en iyi hamlesini seÃ§erek kusursuz ve yenilmez bir oyun sergiler.

## Yazar

**Emre Tantu**
- Website - [emretantu.dev](https://www.emretantu.dev)
- Ä°letiÅŸim - [hello@emretantu.dev](mailto:hello@emretantu.dev)
- LinkedIn - [in/emretantu](https://www.linkedin.com/in/emretantu/)
- Twitter - [@emretantu](https://www.twitter.com/emretantu)